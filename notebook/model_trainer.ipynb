{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf3e1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336fb86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Production\\\\projects\\\\brain_tumor_classification\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183db09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7e6f5339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Production\\\\projects\\\\brain_tumor_classification'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow\n",
    "\n",
    "# DAGsHub credentials\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/hafizshakeel/brain_tumor_classification.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"hafizshakeel\"  # settings -> profile -> username \n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"=**********\"  #  # settings -> tokens \n",
    "\n",
    "# https://dagshub.com/user/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c2abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for gitbash\n",
    "# export MLFLOW_TRACKING_URI=https://dagshub.com/hafizshakeel/brain_tumor_classification.mlflow\n",
    "# export MLFLOW_TRACKING_USERNAME=hafizshakeel \n",
    "# export MLFLOW_TRACKING_PASSWORD==**********\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b790f9d",
   "metadata": {},
   "source": [
    "### Entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d2a9d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    train_data_dir: Path\n",
    "    val_split: float\n",
    "    epochs: int\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    weight_decay: float\n",
    "    optimizer: str\n",
    "    scheduler: str\n",
    "    step_size: int\n",
    "    gamma: float\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b03154",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "from src.brain_tumor_classification import logger\n",
    "from src.brain_tumor_classification.constants import *\n",
    "from src.brain_tumor_classification.utils.common import read_yaml, create_directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "241d8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,\n",
    "                 config_filepath=CONFIG_FILE_PATH,\n",
    "                 params_filepath=PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        config = self.config.training\n",
    "        params = self.params.training\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            trained_model_path=Path(config.trained_model_path),\n",
    "            train_data_dir=Path(config.train_data_dir),\n",
    "            val_split=params.val_split,\n",
    "            epochs=params.epochs,\n",
    "            batch_size=params.batch_size,\n",
    "            learning_rate=params.learning_rate,\n",
    "            weight_decay=params.weight_decay,\n",
    "            optimizer=params.optimizer,\n",
    "            scheduler=params.scheduler,\n",
    "            step_size=params.step_size,\n",
    "            gamma=params.gamma\n",
    "        )\n",
    "        return training_config\n",
    "\n",
    "\n",
    "    def get_mlflow_config(self):\n",
    "        return self.config.mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353b166",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPipeline:\n",
    "    def __init__(self, config: TrainingConfig, model: torch.nn.Module, device, mlflow_config):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        self.mlflow_config = mlflow_config\n",
    "\n",
    "        # Setup MLflow\n",
    "        if self.mlflow_config.log_with_mlflow:\n",
    "            mlflow.set_tracking_uri(self.mlflow_config.mlflow_tracking_uri)\n",
    "            mlflow.set_experiment(self.mlflow_config.mlflow_experiment)\n",
    "\n",
    "        # Transforms\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5], [0.5])\n",
    "        ])\n",
    "\n",
    "        # Dataset + Split\n",
    "        full_dataset = datasets.ImageFolder(self.config.train_data_dir, transform=self.train_transform)\n",
    "        val_size = int(len(full_dataset) * self.config.val_split)\n",
    "        train_size = len(full_dataset) - val_size\n",
    "        self.train_dataset, self.val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "        self.val_dataset.dataset.transform = self.val_transform\n",
    "\n",
    "        # Dataloaders\n",
    "        self.train_loader = DataLoader(self.train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "        self.val_loader = DataLoader(self.val_dataset, batch_size=config.batch_size, shuffle=False)\n",
    "\n",
    "        # Loss, optimizer, scheduler\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        if config.optimizer.lower() == \"adamw\":\n",
    "            self.optimizer = optim.AdamW(self.model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "        elif config.optimizer.lower() == \"sgd\":\n",
    "            self.optimizer = optim.SGD(self.model.parameters(), lr=config.learning_rate, momentum=0.9, weight_decay=config.weight_decay)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown optimizer: {config.optimizer}\")\n",
    "\n",
    "        if config.scheduler == \"step\":\n",
    "            self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=config.step_size, gamma=config.gamma)\n",
    "        elif config.scheduler == \"cosine\":\n",
    "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=config.epochs)\n",
    "        else:\n",
    "            self.scheduler = None\n",
    "\n",
    "        # Save class names (for reports)\n",
    "        self.class_names = full_dataset.classes\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        for images, labels in self.train_loader:\n",
    "            images, labels = images.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        if self.scheduler:\n",
    "            self.scheduler.step()\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = 100. * correct / total\n",
    "\n",
    "        # Log to MLflow\n",
    "        if self.mlflow_config.log_with_mlflow:\n",
    "            mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", epoch_acc, step=epoch)\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch}] Train Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n",
    "        return epoch_loss, epoch_acc\n",
    "\n",
    "    def validate(self, epoch):\n",
    "        self.model.eval()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.val_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = 100. * correct / total\n",
    "\n",
    "        # Log to MLflow\n",
    "        if self.mlflow_config.log_with_mlflow:\n",
    "            mlflow.log_metric(\"val_loss\", epoch_loss, step=epoch)\n",
    "            mlflow.log_metric(\"val_accuracy\", epoch_acc, step=epoch)\n",
    "\n",
    "        logger.info(f\"Epoch [{epoch}] Val Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.2f}%\")\n",
    "\n",
    "        # Metrics (per class)\n",
    "        report = classification_report(all_labels, all_preds, target_names=self.class_names, digits=4, output_dict=True, zero_division=0)\n",
    "        logger.info(f\"\\nClassification Report (Epoch {epoch}):\\n{report}\")\n",
    "\n",
    "        # Log per-class metrics to MLflow\n",
    "        if self.mlflow_config.log_with_mlflow:\n",
    "            for class_name in self.class_names:\n",
    "                if class_name in report:\n",
    "                    mlflow.log_metric(f\"precision_{class_name}\", report[class_name]['precision'], step=epoch)\n",
    "                    mlflow.log_metric(f\"recall_{class_name}\", report[class_name]['recall'], step=epoch)\n",
    "                    mlflow.log_metric(f\"f1_{class_name}\", report[class_name]['f1-score'], step=epoch)\n",
    "\n",
    "        return epoch_loss, epoch_acc, report\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        logger.info(\"Starting Training...\")\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        # Start MLflow run\n",
    "        if self.mlflow_config.log_with_mlflow:\n",
    "            mlflow.start_run()\n",
    "            # Log parameters\n",
    "            mlflow.log_params({\n",
    "                \"epochs\": self.config.epochs,\n",
    "                \"batch_size\": self.config.batch_size,\n",
    "                \"learning_rate\": self.config.learning_rate,\n",
    "                \"weight_decay\": self.config.weight_decay,\n",
    "                \"optimizer\": self.config.optimizer,\n",
    "                \"scheduler\": self.config.scheduler,\n",
    "                \"val_split\": self.config.val_split,\n",
    "                \"model_name\": \"swin_tiny_patch4_window7_224\"\n",
    "            })\n",
    "\n",
    "        try:\n",
    "            for epoch in range(1, self.config.epochs + 1):\n",
    "                train_loss, train_acc = self.train(epoch)\n",
    "                val_loss, val_acc, report = self.validate(epoch)\n",
    "\n",
    "                if val_acc > best_acc:\n",
    "                    best_acc = val_acc\n",
    "                    torch.save(self.model, self.config.trained_model_path)\n",
    "                    logger.info(f\"Best model saved at {self.config.trained_model_path} with Val Acc: {best_acc:.2f}%\")\n",
    "\n",
    "                    # Log best model to MLflow as an artifact (not using mlflow.pytorch.log_model)\n",
    "                    if self.mlflow_config.log_with_mlflow:\n",
    "                        mlflow.log_artifact(self.config.trained_model_path, artifact_path=\"models\")\n",
    "                        mlflow.log_metric(\"best_val_accuracy\", best_acc, step=epoch)\n",
    "\n",
    "            logger.info(\"Training Completed.\")\n",
    "            \n",
    "            # Log the final model as an artifact\n",
    "            if self.mlflow_config.log_with_mlflow:\n",
    "                final_model_path = os.path.join(self.config.root_dir, \"final_model.pth\")\n",
    "                torch.save(self.model, final_model_path)\n",
    "                mlflow.log_artifact(final_model_path, artifact_path=\"models\")\n",
    "                mlflow.log_metric(\"final_val_accuracy\", val_acc)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during training: {e}\")\n",
    "            # Re-raise the exception to ensure it's not silently caught\n",
    "            raise\n",
    "        finally:\n",
    "            if self.mlflow_config.log_with_mlflow:\n",
    "                mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021aa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config_manager = ConfigurationManager()\n",
    "    training_config = config_manager.get_training_config()\n",
    "    mlflow_config = config_manager.get_mlflow_config()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    updated_model_path = config_manager.config[\"prepare_base_model\"][\"updated_model_path\"]\n",
    "    model = torch.load(updated_model_path, map_location=device, weights_only=False)\n",
    "    model = model.to(device)\n",
    "\n",
    "    trainer = TrainingPipeline(config=training_config, model=model, device=device, mlflow_config=mlflow_config)\n",
    "    trainer.run()\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Training failed: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743369b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
